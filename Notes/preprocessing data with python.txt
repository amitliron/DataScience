1. a.columns					- see columns names
2. a.describe()					- see statistics
3. a.dropna()					- remove rows with missing data
4. a.drop([1,2,33]) 			- remove specific rows
5. a.drop("Col_Name", axis=1)   - remove specific col
6. a[a["COL"]==7]				- fillter specific data
7. a["COL"].isnull().sum()		- get num of nulls in specfix column
8. a[a["COL"].notnull()]		- fillter data with null
9. b = a[["col"]]				- select specific column

1. a.dtypes								- check data types
2. a["col"] = a["col"].astype("float")	- change the colum data type

1. a["col"].value_counts()				- count how many diffrent types are there (in order to split for tranning)


general
1. colum - feature

steps:
1. remove null (all or above num of nulls) (rows or columns)
2. change datatypes
3. test the data with 80-20 (split function) (stratified sampling) (in order to avoid from over fitting)

standarization:
1. log normaliztion
2. feature scaling

trainning:
1. score (on test after split)
	1.1 if score is low -> need to think about it
	1.2 may the varient be high -> log normalization (which will minimize the varience)
	1.3 df["col_new"] = np.log(df["col"])
	1.4 df.var()
	
2. check scaling 
	2.1 check max and var for each feature (columnn)
	

sklearn (scikit learn)
1. X_train, X_test, Y_train, Y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)

types:
1. knn (k-nearest neighbors)
2. kmeans
3. base (text clasification)

feature engineering (create new based on exsisting features)
1. enumerate
	1.1 user["subscribe_encoding"] = user["subscribe"].apply(lambda val: 1 if val=="y" else 0)
	    or
		LabelEncoder()
		or (hot encoding)
		pd.get_dummies(user["fav_color"]))
		
2. grouping:
	2.1 columns = ["","", ""]
		df["mean"] = df.apply(lambda row : row[columns].mean(), axis=1)
		
3. dates:
	3.1 df["date_converted"] = pd.to_datetime(df["date"])
	3.2 df["month"] = df["date_converted"].apply(lambda row: row.month)


features from text
1.	import re (regular expression)
2.  pattern = re.compile("\d+\d.\d+")
3.  temp = re.match(pattern, my_string)
4.  temp.group(0)


tf/idf
term frequency
inverse document frequency
